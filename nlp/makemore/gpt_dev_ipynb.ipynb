{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5hjCcLDr2WC",
    "outputId": "ccc60f0c-fd78-4dbe-8598-0512d1036aad"
   },
   "outputs": [],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O6medjfRsLD9"
   },
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xWI_VyAsN8F",
    "outputId": "ed819dd0-72e5-40a6-d2ed-928ff73bfda6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c5V0FvqseE0",
    "outputId": "25ca7adc-b8c0-42d1-b08c-e0863c5c314e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e-Rbyr8sfM8",
    "outputId": "f34e94a9-5b44-4cf3-885b-986731929109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "## Building a GPT\n",
    "\n",
    "Companion notebook to the [Zero To Hero](https://karpathy.ai/zero-to-hero.html) video on GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yw1LKNCgwjj1",
    "outputId": "86fcc21c-2cf7-40d9-cd7b-b5a253da4459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJb0OXPwzvqg",
    "outputId": "db7297cc-36a9-4fae-e941-e7bb9e0e91d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f_WIXqxz0lU5"
   },
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TD5Bj8Y6IAD4",
    "outputId": "bf23c586-1d33-4af1-b63d-ce6f90b0a528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HXDe8vGJCEn",
    "outputId": "588663aa-1de5-4ef7-aba0-4a96fe828353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([812951, 230004, 631457, 285605])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(len(train_data) - block_size, (4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "tensor3 = torch.tensor([7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([tensor1,tensor2,tensor3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tensor1,tensor2,tensor3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([tensor1,tensor2,tensor3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3k1Czf7LuA9",
    "outputId": "4ea8e8a0-443c-49bb-b3bf-ba36e1712999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ix =  tensor([ 76049, 234249, 934904, 560986])\n",
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [24] the target: 43\n",
      "when input is [24, 43] the target: 58\n",
      "when input is [24, 43, 58] the target: 5\n",
      "when input is [24, 43, 58, 5] the target: 57\n",
      "when input is [24, 43, 58, 5, 57] the target: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is [44] the target: 53\n",
      "when input is [44, 53] the target: 56\n",
      "when input is [44, 53, 56] the target: 1\n",
      "when input is [44, 53, 56, 1] the target: 58\n",
      "when input is [44, 53, 56, 1, 58] the target: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52] the target: 58\n",
      "when input is [52, 58] the target: 1\n",
      "when input is [52, 58, 1] the target: 58\n",
      "when input is [52, 58, 1, 58] the target: 46\n",
      "when input is [52, 58, 1, 58, 46] the target: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is [25] the target: 17\n",
      "when input is [25, 17] the target: 27\n",
      "when input is [25, 17, 27] the target: 10\n",
      "when input is [25, 17, 27, 10] the target: 0\n",
      "when input is [25, 17, 27, 10, 0] the target: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    print(\"ix = \", ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpyyAeIzQjlO",
    "outputId": "a650f8dc-da81-400b-bc59-0a595487fdb9"
   },
   "outputs": [],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nql_1ER53oCf",
    "outputId": "5de90b1b-4603-428a-f571-fe4bd3c45436"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTyJ8qAaDdiF"
   },
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs4kI8YdEkQj",
    "outputId": "42ded55c-2983-4d91-c528-675b2edfa849"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100): # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcVIDWAZEtjN",
    "outputId": "0ad6f9d2-ad58-4498-a5f8-6f31407bb18b"
   },
   "outputs": [],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XinV8nmAnmKN"
   },
   "source": [
    "## The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tukiH-NbRBhA",
    "outputId": "d981f6d4-ac08-4ec2-8284-82f5fa1e0815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs_E24uRE8kr",
    "outputId": "8bf3ff5f-565e-48b8-de8e-7272706c8e12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:2+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14900000000000002\n"
     ]
    }
   ],
   "source": [
    "print((0.1808+(-0.3596)+0.6258)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1490, -0.3199])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x[0,:2+1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor(3.5000)\n",
      "tensor([2.5000, 3.5000, 4.5000])\n",
      "tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个二维张量\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float)\n",
    "print(tensor.shape)\n",
    "# 计算整个张量的平均值\n",
    "mean_all = torch.mean(tensor)\n",
    "print(mean_all)  # 输出 tensor(3.5000)\n",
    "\n",
    "# 计算每一行的平均值\n",
    "mean_dim0 = torch.mean(tensor, dim=0)\n",
    "print(mean_dim0)  # 输出 tensor([2.5000, 3.5000, 4.5000])\n",
    "\n",
    "# 计算每一列的平均值\n",
    "mean_dim1 = torch.mean(tensor, dim=1)\n",
    "print(mean_dim1)  # 输出 tensor([2., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "86NuXX0fn7ps"
   },
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhdOAd6-wXkZ",
    "outputId": "eaf6ab61-dff1-4bb7-e623-47f692bad5f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 生成标准正态分布的随机变量\n",
    "z = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# 计算标准正态分布的概率密度函数\n",
    "pdf = norm.pdf(z, loc=0, scale=1)\n",
    "\n",
    "# 绘制图形\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(z, pdf, label='N(0, 1)', color='blue')\n",
    "plt.title('Standard Normal Distribution (Variance = 1)')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOURrfG-ysoL",
    "outputId": "080b500d-8110-4602-fcef-7d6f2ebfc6bc"
   },
   "outputs": [],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDarxEWIRMKq",
    "outputId": "07b587dd-a91c-4bb0-d7f1-e247cd5dacb5"
   },
   "outputs": [],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vT1hdtzXCjgL",
    "outputId": "6d2c569b-7922-451f-9934-0fc564678d17"
   },
   "outputs": [],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5CvobiQ0pLr"
   },
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SNbLq5z3oBw"
   },
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nl6I9n9IRTSo",
    "outputId": "0c5b9cd0-af8a-4564-fbad-41d844e54822"
   },
   "outputs": [],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1tQx7oeRvtc",
    "outputId": "3541ca1a-7447-4ef7-835e-81824aebc1b5"
   },
   "outputs": [],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLb_odHU3iKM",
    "outputId": "a687a222-5a2c-4cdb-c1bf-17cd05b45b69"
   },
   "outputs": [],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JB82yzt44REI",
    "outputId": "f07da2f1-10bb-4a7a-bcaa-578587977d00"
   },
   "outputs": [],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mpt8569BB9_f",
    "outputId": "5d8b910a-6192-44ba-ebb2-497d88e0b629"
   },
   "outputs": [],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Num7sX9CKOH",
    "outputId": "929ceb78-a639-41d6-aac7-12997b5c93f0"
   },
   "outputs": [],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "\n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "633T2cmnW1uk",
    "outputId": "7720fa58-0478-4e8a-86a7-502d4cce9443"
   },
   "outputs": [],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN9cK9BoXCYb",
    "outputId": "6368ece0-600e-417d-8a91-7c1e5d750ba8"
   },
   "outputs": [],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRJH6wM_XFfU"
   },
   "outputs": [],
   "source": [
    "# French to English translation example:\n",
    "\n",
    "# <--------- ENCODE ------------------><--------------- DECODE ----------------->\n",
    "# les réseaux de neurones sont géniaux! <START> neural networks are awesome!<END>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcvKeBXoZFOY"
   },
   "source": [
    "### Full finished code, for reference\n",
    "\n",
    "You may want to refer directly to the git repo instead though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjjvMifYZf7x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
